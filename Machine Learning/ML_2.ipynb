{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-1. Parametric Approach & Hypothesis & Capacity\n",
    "- - -\n",
    "## 종전의 프로그래밍과 머신러닝의 차이점\n",
    "- 전문가 vs. 데이터\n",
    "    - 종전의 프로그래밍은 전문가가 가진 종전의 지식 체계를 이용\n",
    "    - 머신러닝은 데이터를 사용해서 f를 찾아나간다.\n",
    "    \n",
    "## obj : f (Data 기반)\n",
    "- 목표: 데이터에 기반해서 f를 찾는 것\n",
    "<br><br>\n",
    "- 모든 함수가 사는 공간에서 우리가 가지고 있는 데이터를 가장 잘 설명하는 데이터를 찾는다고 가정해보자.\n",
    "    - 이런 접근 방식에는 문제가 있다. 범위가 너무 넓다. 거기에서 하나를 뽑는 건 어렵다.\n",
    "    <br><br>\n",
    "- (우리가 하고 싶은 건) 우리 데이터를 가장 잘 설명하는 함수를 제한된 범위 내에서 찾자\n",
    "    - 모든 1차 함수가 사는 공간에서 우리가 가진 데이터를 가장 잘 설명하는 함수를 찾는 건 그렇게 어려운 일이 아니다.\n",
    "    - 모든 데이터에 대해서 Loss에 계산하고 그걸 다 더해서 Cost를 계산하고 그걸 가장 줄여주는 w와 b를 찾자\n",
    "    <br><br>\n",
    "- Parametric Approach (모수적 접근방법)\n",
    "    - 함수를 찾는 문제 -> Parameter를 찾는 문제로 바뀜\n",
    "    - Parameter = w, b\n",
    "    - 함수를 찾는 문제에서 변수를 찾는 문제로 축소되었다.\n",
    "    <br><br>\n",
    "- Non-Parametric Approach\n",
    "    - Decision Tree\n",
    "<br><br>    \n",
    "- 1차 함수의 한계\n",
    "    - (1차 함수가 사는 공간 안에서) 데이터를 가장 잘 설명하는 함수를 찾았다.\n",
    "    - 1차 함수는 우리가 원하는 관계를 설명하기에는 너무 단순하다.\n",
    "<br><br>\n",
    "- 관심 대상의 확장\n",
    "    - (1차 함수를 포함하는)모든 2차 함수가 사는 공간으로 우리의 관심 대상을 확장\n",
    "    - 확장된 공간에서 우리가 가진 데이터를 가장 잘 설명하는 함수를 찾자.\n",
    "\n",
    "## Hypothesis\n",
    "- 우리가 세운 가설 중에서, 가장 설명력이 뛰어난 w와 b를 찾자는 것!\n",
    "    - Hypothesis를 설정하는 경우의 장점\n",
    "        - 선택할 수 있는 함수의 범위를 크게 줄여준다.\n",
    "        - 모든 함수가 사는 공간에서 뽑는 게 아니라 제한된 영역에서 사는 공간에서 뽑으면 되기에 문제가 훨씬 쉬워진다.\n",
    "        - 함수를 찾는 문제 -> w, b를 찾는 문제로 바뀜 (모수적 접근 방법, Parametric Approach)\n",
    "\n",
    "## Capacity\n",
    "- 1차 함수\n",
    "    - 1차 함수는 Capacity가 부족하다.\n",
    "        - 1차 함수는 우리가 가진 데이터를 표현할 수 있는 능력이 없다.\n",
    "<br><br>\n",
    "- 2차 함수\n",
    "    - (Capacity가 조금 더 높은 2차 함수를 선택해서) 우리가 가진 데이터를 사용해서 러닝 알고리즘을 통해서 가장 데이터를 잘 설명하는 w와 b를 찾자\n",
    "        - 우리가 가진 데이터의 비선형성을 더 잘 설명한다.\n",
    "        - 추세가 일치하는 경향성을 갖다가 우리는 선형성(Linearity - 직선과 비슷한 양상)라고 부른다. \n",
    "        - 데이터를 보면 선형적으로 움직이지 않고, 비선형적으로 움직인다.\n",
    "        - 그래서 비선형적인 관계를 모델링하기 위해서 2차 함수를 사용한다.\n",
    "<br><br>\n",
    "- 3차 함수\n",
    "    - (3차 함수로 우리가 가진 데이터를 모델링 하면) 모델의 성능이 더 좋을 것인가?\n",
    "    - 판단 기준이 Cost였다면, 2차 함수보다 3차 함수가 더 나은 모델이라고 정량적으로 얘기할 수 있다(바로 아래의 Cost 글 참조)\n",
    "<br><br>\n",
    "- Cost\n",
    "    - 모든 데이터의 Loss를 다 더해서 계산한 값이 Cost\n",
    "    - Loss는 예측값과 실제값의 차이를 계산해서 제곱한 값\n",
    "        - loss = (예측 - 실제)^2\n",
    "    - 함수가 늘어나면 Cost가 줄어들게 된다.\n",
    "        - 통계학에서는 R-Squared라고 함.\n",
    "        - 변수를 추가하면 추가할수록 R-Suqared가 낮아진다.\n",
    "    - 판단 기준이 cost였다면, 2차 함수보다 3차 함수가 더 나은 모델이라고 정량적으로 얘기할 수 있다.\n",
    "<br><br>\n",
    "- 질문: 차수가 하나 늘어날 수록 curve가 꺾이는 것인가?\n",
    "    - 꼭 그렇지 않다.\n",
    "\n",
    "# 2-2. Overfitting과 Underfitting\n",
    "- Overfitting (과적합)\n",
    "    - Hypothesis 9 : 9차 함수\n",
    "\t\t- 9차 함수는 Cost가 0이다.\n",
    "        <br><br>\n",
    "\t\t- Cost를 모델의 판단 기준으로 삼기로 했다면, 9차 함수는 좋은 모델이다.\n",
    "        <br><br>\n",
    "\t\t- 허나 (상식적으로 생각한다면) 좋은 모델이 아니다. 왜?\n",
    "\t\t\t- 새로운 Data가 들어오면, 말도 안 되는 수치가 나오기에.\n",
    "            <br><br>\n",
    "\t\t- 그말인 즉슨, __'새로운 데이터에 대한 예측력이 떨어진다'__는 뜻이다.\n",
    "\t\t\t- __우리가 가지고 있는 데이터로 모형(Machine, Model)을 만들어서, 새로운 데이터가 들어왔을 때 잘 예측하는 게 목표인데...__\n",
    "\t\t\t- 우리가 가지고 있는 데이터는 잘 설명하는데(Cost=0이니까), 새로운 데이터에 대한 설명력이 감소한다.\n",
    "\t\t\t- 가지고 있는 데이터로 평가해봤자 아무짝에도 쓸모가 없다\n",
    "\t\t\t- __Overfitting(과적합)__: 과하게 맞추다.\n",
    "<br><br>\n",
    "- Underfitting (오적합)\n",
    "    - 1차 함수는 너무 단순해서, 우리가 가지고 있는 데이터조차 설명을 잘 하지 못한다.\n",
    "<br><br>\n",
    "- 모든 건 다 Capacity 때문에 발생하는 것이다.\n",
    "    - 1차 함수는 Capacity가 너무 낮다, 9차 함수는 Capacity가 너무 높다.\n",
    "\t\t- 1차 함수는 우리가 가지고 있는 데이터 조차 너무 표현하기 어렵고, 9차 함수는 가지고 있는 데이터에 너무 잘 맞춰져 있다.\n",
    "    <br><br>\n",
    "    - 우리는 가장 적절한 Capacity를 찾는 모델이 필요하다.\n",
    "    <br><br>\n",
    "    - ML을 할 때, 일반적으로 Underfitting은 잘 안 일어난다. 왜냐면 우리가 사용하는 모델들이 기본적으로 Capacity가 높기 때문에.\n",
    "    <br><br>\n",
    "    - Overfitting이 정말 많이 일어난다. 극도로 경계해야하는 문제.\n",
    "\t\t- ML System을 Design할 때, 가장 신경써서 해결해야 할 문제가 Overfitting이다.\n",
    "\t\t\t- ex) 금융 : 삼성전자 주식 (2010~2017년) 데이터로 모델을 만들어서 내일의 주가를 예측하면? -> 망한다.\n",
    "\t\t\t- 금융에서는 __백테스팅__을 한다. 우리가 배우는 개념을 금융에서는 백테스팅이라고 부른다.\n",
    "<br><br>\n",
    "- Overfitting 문제를 해결해야 한다.\n",
    "    - 해결 방안 1\n",
    "\t\t- 데이터를 많이 모은다. Capacity 높은 모델에 Big Data를 때려 넣는다.\n",
    "<br><br>\n",
    "- __Underfitting, Overfitting은 상대적이다.__\n",
    "    - 1,000개의 데이터에 99,000개를 모아서 넣는다면, 1000개의 데이터에서 관측하지 못했던 새로운 구조가 드러난다. \n",
    "\t\t- 그러면 1, 3, 9차 함수를 통해서 우리가 가진 데이터를 모델링 해보자!\n",
    "\t\t\t- 1, 3, 9차 함수 모두 우리가 가진 데이터의 구조를 잘 표현하지 못했다. (Underfitting)\n",
    "<br><br>    \n",
    "- 언제 Overfitting / Underfitting 비교할 수 있는 정량적인 양을 [Bayes Error](http://newsight.tistory.com/127)라고 한다.\n",
    "<br><br>\n",
    "- Underfitting의 문제\n",
    "    - 데이터를 빼야할까?\n",
    "\t\t- 그건 좋은 방법이 아니다.\n",
    "        <br><br>\n",
    "    - 구조를 더 잘 모델링하기 위해서 (무지막지하게) 차수를 높이면 된다?\n",
    "\t\t- 근데 그것도 좋은 방법이 아니다.\n",
    "\t\t- (0.01)^100 = 1e-200 (10에 - 200승, 10에 200승 분의 1)\n",
    "        <br><br>\n",
    "    - Overflow와 Underflow 문제\n",
    "\t\t- Underflow : 다 0이라고 계산하는 문제\n",
    "\t\t- Overflow : 예를 들어서 컴퓨터가 표현할 수 있는 수가 -10000 ~ 10000까지 인데, 10001을 입력하면 컴퓨터는 10001이 아니라 -10000으로 인식하는 문제가 발생\n",
    "        <br><br>\n",
    "    - 지금의 경우는 Underflow의 문제가 발생할 수 있다.\n",
    "    <br><br>\n",
    "    - (좋은 머신이 있으면 문제가 없겠지만) 단순히 차수를 높여가는 모델은 한계가 있을 수 밖에 없다. 좋은 아이디어가 아니다.\n",
    "    <br><br>\n",
    "    - 그래서 우리는 신경망 모델이나 의사결정나무에 기반한 모델을 사용한다.\n",
    "<br><br>\n",
    "- 신경망 / 의사결정나무 / 랜덤포레스트\n",
    "    - 다층퍼셉트론\n",
    "    <br><br>\n",
    "    - 의사결정나무\n",
    "    <br><br>\n",
    "    - 랜덤포레스트 : 의사결정나무 수천 개를 평균해서 만든 것\n",
    "    <br><br>\n",
    "    - 현업에서 사용한다면 랜덤포레스트가 좋다.\n",
    "\t\t- 위에 모델들은 9차 함수보다 좋은 성능을 보인다.\n",
    "    <br><br>\n",
    "    - 그래서 우리는 Capacity가 높은 모델군들이 필요하다.\n",
    "\t\t- 우리가 더 많은 모델을 배우고자 하는 이유\n",
    "<br><br>\n",
    "- 데이터가 충분히 많아지면, 숨겨졌던 구조가 더 잘 드러나게 된다.\n",
    "    - 데이터의 구조가 복잡하고, 데이터가 많기만 하면 뭐하나?\n",
    "\t\t- 그 구조를 정확하게 모델링할 수 있는, 정확하게 표현할 수 있는, 그 능력(Capacity)을 가진 모델들이 필요한 것\n",
    "\t\t- 그게 흔히 Deep Learning이 해주는 일이다.\n",
    "\t\t- 딥러닝 모델의 Capacity는 어마어마하게 크다.\n",
    "\t\t- 그래서 두 개가 만났을 때, 좋은 성능을 보여준다.\n",
    "<br><br>\n",
    "- 데이터가 (상대적으로) 적은데, 모델 Capacity가 (상대적으로) 작다. 그러면 Underfitting의 문제가 일어난다.\n",
    "    - 근데 실제로는 잘 일어나지 않는다.\n",
    "<br><br>    \n",
    "- (상대적으로) 데이터가 충분히 많지 않음에도 불구하고, 모델 Capacity가 너무 커버리면 Overfitting의 문제가 발생한다. \n",
    "    - 이런 문제가 더 자주 발생하고, 더 중요하다.\n",
    "    - __데이터의 수, Capacity는 상대적이다__\n",
    "\n",
    "## __Overfitting의 문제를 해결하려면__\n",
    "- 1) __데이터를 무지하게 많이 모으면 된다.__\n",
    "<br><br>\n",
    "- 2) (더 모을 수 없는 상황이라면) __모델 Capacity를 제한__하면 된다.\n",
    "    - 더 작은 차수를 쓰도록 Hypothesis를 바꿔준다.\n",
    "<br><br>\n",
    "- 3) (그게 아니라면) __9차 함수를 쓰기는 쓰되, 러닝 알고리즘을 바꿔준다.__\n",
    "    - 학습하는 과정에서 우리가 가진 데이터에 너무 잘 맞지 않게끔 패널티를 줄 수 있다.\n",
    "    - [regularization](http://gnujoow.github.io/ml/2016/01/30/ML4-Regularization/)\n",
    "\n",
    "### Overfitting 해결 방안, 1줄 요약\n",
    "    - 데이터를 만들거나, 더 작은 차수의 모델을 쓰거나, 함수의 차수를 그대로 쓰되 러닝 알고리즘을 변경하면 된다.\n",
    "<br><br>\n",
    "- 질문\n",
    "    - Cost Function\n",
    "\t\t- Cost Function 값을 가지고 아무 것도 판단할 수 없다.\n",
    "\t\t- 판단할 수 있는 유일한 건 우리가 선택한 모델이 우리가 가진 데이터를 얼마나 잘 설명했는가?\n",
    "\t\t- __어떤 모델이 좋고 나쁜지를 가리기 위해서 새로운 선택 기준이 필요하다.__\n",
    "\t\t- 그걸 Cost라 안 하고 앞으로 Train이라고 한다.\n",
    "- - -\n",
    "# 2-3. Cross - Validation\n",
    "\n",
    "- [ISLR](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20First%20Printing.pdf)\n",
    "    - 1~4단원 차례대로 읽고, 7단원은 반드시 읽기\n",
    "    - Model Assessment and Selection\n",
    "    - 우리가 선택한 모델들을 어떻게 평가하고 선택할 것인지\n",
    "        - Bias, Variance, Bayesian Approach\n",
    "        - __Cross-Validation(교차검증)__\n",
    "<br><br>\n",
    "- 책 추천\n",
    "    - [가볍게 시작하는 통계학습](http://www.aladin.co.kr/shop/wproduct.aspx?ItemId=81859233)\n",
    "    - [해들리 위컴의 Advanced R](http://www.aladin.co.kr/shop/wproduct.aspx?ItemId=143252067)\n",
    "    - [핸즈온 머신러닝](http://www.aladin.co.kr/shop/wproduct.aspx?ItemId=142196914)\n",
    "\n",
    "\n",
    "### [실습 1](http://localhost:8888/notebooks/Downloads/dev/study/R_ML/Class%202/ML_2_script.ipynb)\n",
    "- - -\n",
    "## [Statistical Learning Theory]\n",
    "\n",
    "## Training Error (이하 T.R)\n",
    "- training set: 모델을 훈련시키는데 사용하는 데이터\n",
    "<br><br>\n",
    "- training set을 사용해서 학습 시킨 모델이 우리가 가진 training set을 얼마나 잘 설명하고 있는지를 나타내주는 척도\n",
    "<br><br>\n",
    "- (cost값은 cost값인데) 학습이 끝난 후의 cost값이다.\n",
    "<br><br>\n",
    "- model의 Capacity가 높아지면 높아질수록 training error는 무조건 줄어든다.\n",
    "<br><br>\n",
    "    - Capacity가 높아진다는 건 모델의 기억력이 늘어난다는 얘기와 같음\n",
    "    <br><br>\n",
    "    - 모델의 기억력이 늘어난다는 건,\n",
    "\t\t- (모델이) train set을 암기해버리는 사태가 발생한다.\n",
    "\t\t- 그게 바로 __overfitting__\n",
    "\t\t- 나는 암기하는 게 아니라 실제로 training set을 이해하고, 일반화 시켜주는 작업을 모델에다 시키고 싶은 건데\n",
    "\t\t- Capacity가 높으면 단순히 암기하는 결과를 내뱉어주는 암기 머신에 불과하다.\n",
    "\t\t- 그 경우가 overfitting이고, 우리는 그 경우를 방지해야 한다. \n",
    "\n",
    "## Generalization Error (일반화 오류, 이하 G.E)\n",
    "- 모델이 training set을 가지고 일반화를 했는데, 그 일반화한 결과에 얼마나 오류가 있을 것인가에 대한 양\n",
    "<br><br>\n",
    "- 그런데 일반적으로 측정할 수가 없는 양이다.\n",
    "    - 새로운 데이터가 없다는 뜻으로, 일반적으로는 측정이 불가능하다.\n",
    "<br><br>\n",
    "- Generalization Error 대신에 우리는 Data를 두 개로 쪼갠다.\n",
    "    - 그래서 G.E를 어떤 식으로 추측(추정)할 것인지 배워볼 것이다.\n",
    "    - 그전에 이거부터 배울 것이다.\n",
    "<br><br>\n",
    "- 우리는 이전에 모델한테 '우리가 가진 training set을 가장 잘 설명하는 함수를 찾아봐'라고 얘기해줬다.\n",
    "<br><br>\n",
    "    - training error(cost function)의 최소화\n",
    "    <br><br>\n",
    "    - 우리가 실제로 하고 싶었던 건, __training error를 낮추는 게 아니라, generalization error를 제일 낮추는 것__이었다.\n",
    "    <br><br>\n",
    "    - __일반적으로 G.E를 낮추는 건 불가능__하다.\n",
    "    <br><br>\n",
    "    - GE를 낮추고 싶지만, 그럴 수 없으니까 __대신에 T.E를 낮추는 모델__을 만들기로 함\n",
    "    <br><br>\n",
    "    - 그렇게 선택한 모형이 과연 G.E도 낮출 것인가?\n",
    "    <br><br>\n",
    "    - 아니라면 그 둘은 얼마나 차이가 날 것인가?\n",
    "    <br><br>\n",
    "    - 그걸 이론적으로 분석한 학문이 statistical learning theory다.\n",
    "\n",
    "## Statistical Learning Theory 부등식\n",
    "- 통계적 학습이론에서 가장 중요한 부등식\n",
    "<br><br>\n",
    "- G.E는 T.E보다 높을까 낮을까?\n",
    "<br><br>\n",
    "    - training set을 우리가 모델을 training하는데 썼으니까 당연히 모델은 training error는 낮을 것이다(낮추는 방향으로 학습했으니까!)\n",
    "    <br><br>\n",
    "    - 새로운 데이터가 들어오면 에러는 당연히 T.E보다 높을 수밖에 없다.\n",
    "    <br><br>\n",
    "    - 그러면 얼마나 높을 것인가?\n",
    "\n",
    "## Basic Terminology\n",
    "- 새로운 데이터를 구하기 어려우니까, 기존의 데이터를 나눠서 훈련으로 모델링을 한 다음에 테스트를 한다!\n",
    "<br><br>\n",
    "- 일반적으로 G.E가 T.R보다는 높다.\n",
    "<br><br>\n",
    "    - 부등식이 말해주는 건, T.R보다는 커도, T.R + @ 보다는 작다는 것이다.\n",
    "    <br><br>\n",
    "    - __TR + e >= G.E >= T.R(training error)__\n",
    "\t\t-  영희의 키(168) + e >= 철수의 키 >= 영희의 키(168) ??\n",
    "        <br><br>\n",
    "    - e의 값이 작으면 작을수록 좋겠다.\n",
    "\t\t- 영희의 키에 더해주는 'e' 값이 작으면 작을수록 철수의 키를 더 정확하게 말할 수 있다.\n",
    "        <br><br>\n",
    "    - 우리는 e값이 작아지기를 원한다.\n",
    "    <br><br>\n",
    "    - 작아야 G.E가 저 범위 안에 들어갈 것이라는 것을 Guarantee할 수 있으니까\n",
    "    <br><br>\n",
    "    - n은 트레이닝 데이터의 개수\n",
    "\t\t- 데이터를 많이 모으면 좋은 것.\n",
    "\t\t- __데이터를 많이 모으면 루트 안의 값이 작아진다(값이 낮으면 좋은 것).__\n",
    "        <br><br>\n",
    "    - D는 model의 capacity임.\n",
    "\t\t- D가 커지면 루트 안의 값이 커진다.\n",
    "\t\t- __이 값을 줄이기 위해서는 데이터를 많이 모아야 하고, capacity를 줄여야한다.__\n",
    "        <br><br>\n",
    "- 왜 그런 결과들이 발생했는지 이론적으로 조금이나마 이해해볼 수 있게 되었다.\n",
    "<br><br>\n",
    "- 얘는(?) 데이터가 많으니까(n이 크니까), 루트 안의 값이 작아져서 G.E와 T.R 거의 비슷해졌다. 그러니까 overfitting이 발생하지 않았다고 해석할 수 있게 되었다.\n",
    "\n",
    "## Structural Risk Minimization & Empirical Risk Minimization\n",
    "- Training error를 줄이는 게 아니라, e값을 줄여버리면 되지 않겠느냐?\n",
    "    - __Structural Risk Minimization__ (구조적 위협을 최소화하는 것)\n",
    "    <br><br>\n",
    "- 계산하는 게 너무 어렵기 때문에, T.R를 최대한 줄여라. 그러면 그 모델의 G.E도 작을 것이다.\n",
    "    - T.R를 줄이는 방향으로 학습시키는 방법 : __Empirical Risk Minimization__ (경험적인)\n",
    "\t\t- 관측할 데이터를 가지고 loss(cost)를 최소화 시켜라.\n",
    "\t\t- 그렇게 만든 모델이 새로운 데이터에 대한 예측력도 나쁘지 않을 것이라고 생각하고 학습을 시킴\n",
    "\t\t- 머신러닝에서 무조건 이 방법을 사용함\n",
    "\n",
    "## 요약\n",
    "- 모델의 capacity가 높아지면 기억력이 좋아지기 때문에 Training Error는 무조건 줄어든다.\n",
    "- (일반화된 결과를 뱉어줘야 하는데, 암기한 결과만 뱉어주니까) 새로운 데이터에 대한 예측력이 떨어진다.\n",
    "- Generalization Error를 제일 낮추는 optimal한 최적의 capacity를 찾자!\n",
    "- - -\n",
    "# 2-4. K-Fold Cross Validation\n",
    "### 대부분의 사람들이 실수하는 개념\n",
    "- 768개의 Data Set이 있다면 ...\n",
    "    - 일반적으로 70%는 Training Set, 30%는 Test Set으로 나눈다.\n",
    "    - Training Set을 통해 학습하고, 학습한 모델이 나온다.\n",
    "    - Test Set에는 Input도 있고 Output도 있다.\n",
    "\t\t- Test set에 있는 Input을 기계(모형)에 넣어서 Output을 예측하게 한 다음에\n",
    "\t\t- 두 개가 얼마나 차이가 나는지 본다.\n",
    "\t\t\t- maen((y - y_hat)^2)\n",
    "\t\t\t- y는 실제값, y_hat은 예측값(추정치)\n",
    "<br><br>\n",
    "    - mean(y - y_hat_n)^2\n",
    "\t\t- 거기에서 나온 게 Test Error\n",
    "\t\t\t- Test Error가 가장 낮은 모형을 선택해야 할까?\n",
    "\t\t\t- Training Error는, 높은 차수의 모델이 가장 낮을 것이지만\n",
    "\t\t\t- Test Error는 그렇지 않다.\n",
    "\t\t\t- 그래서 우리는 Test Set에 대한 Error가 가장 낮아지는 모형을 선택할 것인가?\n",
    "\t\t\t- 틀린 이야기다.\n",
    "<br><br>\n",
    "    - Generalization Error는 측정할 수 없다.\n",
    "        - 측정할 새로운 데이터가 없기에, 대신에 우리가 가지고 있는 train set을 두 개로 쪼개서 하나는 train set, test set으로 만든다.\n",
    "        - 새로운 데이터를 모델이 얼마나 잘 예측하는지 보겠다는 것.\n",
    "<br><br>\n",
    "- Generalization Error에 대한 추정치가 Test Error(T.R)다.\n",
    "    - T.R는 G.E를 최대한 정확하게 추정하기 위해서 필요한 세트다.\n",
    "    - T.R와 G.E는 최대한 비슷해야 된다.\n",
    "\n",
    "### [실습 2](http://localhost:8888/notebooks/Downloads/dev/study/R_ML/Class%202/ML_2_script.ipynb)\n",
    "- 샘플의 수가 적으면 ... (2시간 12분 20초)\n",
    "> - 트레이닝 셋을 임의로 k등분함.\n",
    "> - 이 알고리즘은 cross vailation\n",
    "\n",
    "- loocv는 k-fold CV보다 안 좋다.\n",
    "\n",
    "- 논리의 흐름 (2시간 21분 53초)\n",
    "> - test set의 역할은 G.E를 최대한 정확하게 추정하는데 본질이 있다.\n",
    ">> - G.E: 모델을 트레이닝하는데 사용하지 않은 데이터의 에러\n",
    ">> - 각각의 모델의 test를 확인하고, 가장 작은 걸 선택한다.\n",
    ">> - 세 개의 모델 중에서 마지막 모델을 선택했다는 건, 직접적으로 트레이닝 셋을 사용한 것이다.\n",
    ">> - 세 개의 모델 중에 하나를 선택하는 과정 중에 우리는 무엇을 사용했는가?\n",
    ">>> - test set 사용함. 10차 함수는 간접적으로 test set본 것과 다름 없다.\n",
    ">>> - test set은 모델이 전혀 본적이 없는 데이터를 추정하는데 쓰이는 게 본질\n",
    ">>> - 허나 봤음... test set이 오염 됐다.\n",
    ">>> - 다른 데이터가 있어야 한다. 그래서 데이터가 2등분이 아니라 3등분을 해야한다.\n",
    "> - test set과 또 다른 데이터 셋이 필요하다! (2시간 26분)\n",
    ">> - Training set // Validation Set // Test Set\n",
    ">>> - Train Set: 모델 훈련, Valid set: 모델을 추정하고 선택 \n",
    ">>> - 최종적으로 GE를 정확하게 추정되는데 사용하는 데이터가 Test Set\n",
    ">>> - 연구 윤리: Test Set을 최종적으로 써야 한다.\n",
    "- [ibm 왓슨 아주대병원](http://news.chosun.com/site/data/html_dir/2018/01/10/2018011002828.html) (2시간 29분)\n",
    "> - 통계적으로 bias 되는 현상이 발생한다.\n",
    "> - test set은 끝까지, 최후까지 나눠둬야 한다.\n",
    "\n",
    "- 질문 (2시간 31분)\n",
    "- 데이터를 나누는 비율\n",
    "> - (중규모) 6:2:2 / (대규모) 9:1 or 8:2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
