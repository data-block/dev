{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. 라이브러리 호출\n",
    "import time # 시간 딜레이 및 코드 진행 시간 측정을 위한 라이브러리\n",
    "import math # 리뷰 한 페이지당 10개의 리뷰가 있는데, 딱 떨어지지 않는 경우가 많아서(ex: 2433일 경우에 244 페이지) 올림 처리하여 모든 리뷰 수집을 위한 라이브러리\n",
    "import requests # 서버에 요청하는 라이브러리  (from urllib.request import urlopen)을 사용해도 무방\n",
    "import pandas as pd # 추후에 손쉽게 확인하기 위한 라이브러리 (pandas, dataframe)\n",
    "from bs4 import BeautifulSoup # 예쁘게 꾸며주는 라이브러리\n",
    "import datetime\n",
    "\n",
    "dt = datetime.datetime.now()\n",
    "dt\n",
    "\n",
    "## 2. 다운로드 함수를 만들기 위한 사전 작업\n",
    "# movieId_list에 수집하고 싶은 영화의 ID 값을 입력\n",
    "# movieId는 다음 영화 페이지에서 개발자 도구를 통해 얻을 수 있음 (tag: movieId)\n",
    "movieId_list = ['93251', '102301', '106954', '116628', '109076'] # 5개의 영화\n",
    "page = '1' # 리뷰 페이지 (1~n)\n",
    "movie_list = [] # 영화 정보들을 담을 리스트 ... [{'key1' : 'val2', 'key2' : 'val2' ... 의 형태로 담김}]\n",
    "\n",
    "# 영화 정보를 담기 위한 반복문 작업\n",
    "for movieId in movieId_list:\n",
    "    base_url = \"http://movie.daum.net/moviedb/grade?movieId=\"\n",
    "    url = 'http://movie.daum.net/moviedb/grade?movieId=' + movieId + '&type=netizen&page=' + page # 인자 값으로 movieId와 page를 받음\n",
    "    # requests 함수를 사용하여 서버에 호출\n",
    "    resp = requests.get(url)\n",
    "    # beautifulsoup을 사용하여 파싱\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    # 리뷰 숫자 카운트\n",
    "    review_no = soup.find(\"span\", {\"class\": \"txt_menu\"}).get_text()\n",
    "    review_no = int(review_no.replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\"))\n",
    "    # 페이지 수 카운트\n",
    "    page_no = math.ceil(review_no / 10)\n",
    "    # 정확한 영화 제목을 얻기 위한 변수\n",
    "    movie_nm = soup.find(\"h2\", {\"class\" : \"tit_rel\"}).get_text()\n",
    "\n",
    "    # movie_list에 사전 형태로 영화의 정보 담기\n",
    "    # movieId : 영화 번호(고유값) / movie_nm : 영화 제목 / base_url: parameter 전의 기본 url / url: parameter를 포함한 url / review_no : 리뷰 숫자 / page_no: 페이지 숫자\n",
    "    movie_list.append({\n",
    "        'movieId': movieId,\n",
    "        'movie_nm': movie_nm,\n",
    "        'base_url': base_url,\n",
    "        'url' : url,\n",
    "        'review_no': review_no,\n",
    "        'page_no': page_no\n",
    "    })\n",
    "print(movie_list)\n",
    "\n",
    "## 3. 다운로드 함수 정의\n",
    "def daum_movie():\n",
    "    # 코스 실행 시간 측정 (st_dt: 시작, ed_dt: 종료, run_dt: 실행시간)\n",
    "    st_dt = time.time()\n",
    "    # 크롤링한 데이터를 담기 위한 txt 파일 생성\n",
    "    fout = open(\"./daum_movie_result({}).txt\".format(dt.strftime(\"%Y%m%d\")), 'w', encoding = 'utf-8')\n",
    "    # fout = open(\"./daum_movie_result.txt\", 'w', encoding = 'utf-8')\n",
    "\n",
    "    # movie_list에 담긴 5개의 영화를 반복문으로 돌리기\n",
    "    for movie in movie_list:\n",
    "        movie_nm = movie.get('movie_nm')\n",
    "        review_no = movie.get('review_no')\n",
    "        page_no = movie.get('page_no')\n",
    "        base_url = movie.get('base_url')\n",
    "        movie_id = movie.get('movieId')\n",
    "\n",
    "        # 진행상황을 알고 싶다면 print문의 주석 해제\n",
    "        # print('movie_nm : ', movie_nm)\n",
    "        # print('movie_id : ', movie_id)\n",
    "        # print('review_no : ', review_no)\n",
    "        # print('page_no : ' , page_no)\n",
    "\n",
    "        fout.write(\"movie_nm : \" + movie_nm + \"(\" + str(review_no) + \")\"+ \"\\n\")\n",
    "        for page in range(1, page_no + 1):\n",
    "            url = base_url + movie_id + '&type=netizen&page=' + str(page)\n",
    "            print(movie_nm, \" : \", page, \"/\", page_no)\n",
    "\n",
    "            resp = requests.get(url)\n",
    "            soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "            reviews = soup.find_all('p', {'class': 'desc_review'})  \n",
    "\n",
    "            # response = urlopen(url)\n",
    "            # parsed = BeautifulSoup(response, 'html.parser')  # 'html5lib'을 사용해도 무방하나 'html.parser'가 더 빠름\n",
    "            # reviews = parsed.find_all('p', {'class': 'desc_review'})\n",
    "            \n",
    "            for review in reviews:\n",
    "                review = review.get_text(strip = True)\n",
    "                if review != \"\":\n",
    "#                     print(review)\n",
    "\n",
    "                    fout.write(review + \"\\n\")\n",
    "        fout.write(\"=\"*30 + \"\\n\")\n",
    "    fout.close()\n",
    "    ed_dt = time.time()\n",
    "\n",
    "    print(\"--- {} seconds ---\".format(ed_dt - st_dt))\n",
    "\n",
    "daum_movie()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
